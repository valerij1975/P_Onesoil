{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В этом блокноте кратко описано использование Google BigQuery для выполнения некоторых задач по данной теме**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План действий\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем в BigQuery исходные CSV-файлы.\n",
    "\n",
    "- сначала загружаем CSV в google storage;\n",
    "- затем создаем датасет olist и вручную через консоль создаем в нем таблицы на основе этих CSV-файлов.\n",
    "- (примечание: делаем это вручную, так как это разовая задача и так быстрее. Если будет задача обрабатывать регулярно поступающие порции данных, то это можно сделать например через Pub/Sub или другими способами)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка дубликатов строк и уникальности ключевых полей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# полные дубликаты строк - выдает строки, которые встречаются более 1 раза\n",
    "\"\"\"\n",
    "SELECT \n",
    "  COUNT(*) as num_duplicate_rows, * \n",
    "  FROM <PROJECT_ID>.olist.closed_deals\n",
    "GROUP BY\n",
    "  mql_id, seller_id, sdr_id, sr_id, won_date, business_segment, lead_type, lead_behaviour_profile, \n",
    "  has_company, has_gtin, average_stock, business_type, declared_product_catalog_size, declared_monthly_revenue \n",
    "HAVING num_duplicate_rows > 1;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дубликаты строк по указанным столбцам - выдает строки, которые встречаются более 1 раза. Для проверки уникальности ключей\n",
    "\"\"\"\n",
    "SELECT \n",
    "  COUNT(*) as num_duplicate_rows,\n",
    "  mql_id\n",
    "  FROM <PROJECT_ID>.olist.closed_deals\n",
    "GROUP BY\n",
    "  mql_id\n",
    "HAVING num_duplicate_rows > 1;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Уникальные ключи в таблицах:**\n",
    "\n",
    "- closed_deals: mql_id\n",
    "- customers: customer_id\n",
    "- geolocation: нет уникального ключа\n",
    "- marketing_qualified_leads: mql_id\n",
    "- order_items: (order_id, order_item_id)\n",
    "- order_payments: (order_id, payment_sequential)\n",
    "- order_reviews: (review_id, order_id)\n",
    "- orders: order_id или customer_id\n",
    "- product_category_name_translation: product_category_name\n",
    "- products: product_id\n",
    "- sellers: seller_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество уникальных значений по указанному полю\n",
    "\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  COUNT(*) AS total_rows,\n",
    "  COUNT(DISTINCT sdr_id ) AS unique_sdr,\n",
    "FROM <PROJECT_ID>.olist.closed_deals ;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перечень уникальных значений\n",
    "\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  DISTINCT sdr_id AS unique_sdr\n",
    "FROM <PROJECT_ID>.olist.closed_deals ;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL-запросами объединяем таблицы и сохраняем их в качестве стационарных\n",
    "\n",
    "**Для отладки и контроля появления ошибок при соединениях таблиц сначала делаю простые запросы, проверяя из правильность. Затем свожу их в единый запрос**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORDER-ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# к таблице sellers добавляем средние долготу и широту по ZIP-коду\n",
    "\"\"\"\n",
    "#standardSQL\n",
    "WITH geoavg AS (SELECT \n",
    "  geolocation_zip_code_prefix,\n",
    "  AVG(geolocation_lat) AS lat,\n",
    "  AVG(geolocation_lng) AS lng\n",
    "FROM celestial-digit-321306.olist.geolocation\n",
    "GROUP BY\n",
    "    geolocation_zip_code_prefix)  \n",
    "\n",
    "\n",
    "SELECT \n",
    "    s.*, \n",
    "    geoavg.lat AS sellers_geo_lat,\n",
    "    geoavg.lng AS sellers_geo_lng\n",
    "FROM <PROJECT_ID>.olist.sellers s LEFT JOIN geoavg ON s.seller_zip_code_prefix=geoavg.geolocation_zip_code_prefix;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# к таблице sellers_geo добавляем инфу из closed_deals\n",
    "\"\"\"\n",
    "#standardSQL\n",
    "SELECT \n",
    "    s.*, \n",
    "    c.* EXCEPT(seller_id)\n",
    "FROM <PROJECT_ID>.olist.sellers_geo s LEFT JOIN <PROJECT_ID>.olist.closed_deals c ON s.seller_id=c.seller_id;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# к order_items добавляем инфу по поставщикам (seller) и продукту (products)\n",
    "\"\"\"\n",
    "#standardSQL\n",
    "WITH \n",
    "oit AS (SELECT \n",
    "    ord.*, \n",
    "    s.* EXCEPT(seller_id)\n",
    "FROM <PROJECT_ID>.olist.order_items ord LEFT JOIN <PROJECT_ID>.olist.sellers_full s ON ord.seller_id=s.seller_id),\n",
    "\n",
    "prod AS (SELECT \n",
    "    p.*, \n",
    "    pc.product_category_name_english AS prod_cat_en\n",
    "FROM <PROJECT_ID>.olist.products p LEFT JOIN <PROJECT_ID>.olist.product_category_name_translation pc ON p.product_category_name=pc.product_category_name)\n",
    "\n",
    "SELECT\n",
    "    oit.*, \n",
    "    prod.* EXCEPT(product_id)\n",
    "FROM oit LEFT JOIN prod ON oit.product_id=prod.product_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Итоговый запрос для создания расширенной таблицы order_items1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# к таблице sellers добавляем средние долготу и широту по ZIP-коду\n",
    "\"\"\"\n",
    "#standardSQL\n",
    "WITH geoavg AS (SELECT \n",
    "  geolocation_zip_code_prefix,\n",
    "  AVG(geolocation_lat) AS lat,\n",
    "  AVG(geolocation_lng) AS lng\n",
    "FROM celestial-digit-321306.olist.geolocation\n",
    "GROUP BY\n",
    "    geolocation_zip_code_prefix),  \n",
    "\n",
    "selzip AS (\n",
    "SELECT \n",
    "    s.*, \n",
    "    geoavg.lat AS sellers_geo_lat,\n",
    "    geoavg.lng AS sellers_geo_lng\n",
    "FROM <PROJECT_ID>.olist.sellers s LEFT JOIN geoavg ON s.seller_zip_code_prefix=geoavg.geolocation_zip_code_prefix),\n",
    "\n",
    "selzipclose AS (\n",
    "SELECT \n",
    "    s.*, \n",
    "    c.* EXCEPT(seller_id)\n",
    "FROM selzip s LEFT JOIN <PROJECT_ID>.olist.closed_deals c ON s.seller_id=c.seller_id),\n",
    "\n",
    "\n",
    "oit AS (SELECT \n",
    "    ord.*, \n",
    "    s.* EXCEPT(seller_id)\n",
    "FROM <PROJECT_ID>.olist.order_items ord LEFT JOIN selzipclose s ON ord.seller_id=s.seller_id),\n",
    "\n",
    "prod AS (SELECT \n",
    "    p.*, \n",
    "    pc.product_category_name_english AS prod_cat_en\n",
    "FROM <PROJECT_ID>.olist.products p LEFT JOIN <PROJECT_ID>.olist.product_category_name_translation pc ON p.product_category_name=pc.product_category_name)\n",
    "\n",
    "SELECT\n",
    "    oit.*, \n",
    "    prod.* EXCEPT(product_id)\n",
    "FROM oit LEFT JOIN prod ON oit.product_id=prod.product_id\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORDER-REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем результаты обработки в Google Natural Language API и сохраняем в стационарную таблицу order_reviews2, чтобы не запускать постоянно большой запрос\n",
    "\"\"\"\n",
    "SELECT \n",
    "    s.*, \n",
    "    g.sent_score,\n",
    "    g.sent_magnitude,\n",
    "    g.entities_list,\n",
    "    g.sentences_count,\n",
    "    g.token_count,\n",
    "    g.sentlist,\n",
    "    g.tokenlist\n",
    "FROM <PROJECT_ID>.olist.order_reviews s LEFT JOIN <PROJECT_ID>.olist.order_reviews_googleapi g \n",
    "ON s.review_id=g.review_id AND s.order_id=g.order_id;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в order-reviews есть часть заказов, по которым оставлено 2-3 отзыва. (547 заказов), из которых с текстовыми описаниями только 244. \n",
    "# и в основном это просто история переписки по заказу, в результате которой оценка может улучшиться, ухудшиться или остаться прежней\n",
    "\"\"\"\n",
    "SELECT \n",
    "  COUNT(*) as num_duplicate_rows,\n",
    "  SUM(LENGTH(message1)) as len_mes,\n",
    "  order_id\n",
    "  FROM <PROJECT_ID>.olist.order_reviews\n",
    "\n",
    "GROUP BY\n",
    "  order_id\n",
    "\n",
    "HAVING num_duplicate_rows > 1\n",
    "ORDER BY len_mes\n",
    "\"\"\"\n",
    "# поэтому для обработки отзывов используем следующий подход: \n",
    "# агрегируем по order-id. При этом из дат делаем 4 столбца (дата первого запроса и ответа на него, дата последнего запроса и ответа на него)\n",
    "# оценку берем по последней дате. Соответственно и результаты из API google берем из последней даты: здесь логика следующая - именно последний отзыв\n",
    "# можно считать как финальное состояние удовлетворенности клиента. \n",
    "# текстовые значения в title и message объединяем в строки по ордеру\n",
    "# добавляем поле \"количество рецензий на ордер\"\n",
    "# и затем полученную агрегированную таблицу добавляем к orders\n",
    "# этот запрос реализует данную логику\n",
    "\"\"\"\n",
    "WITH tmp AS (\n",
    "SELECT \n",
    "  MAX(review_answer_timestamp) as max_review_answer_date,\n",
    "  order_id\n",
    "  FROM `<PROJECT_ID>.olist.order_reviews2`\n",
    "GROUP BY\n",
    "  order_id),\n",
    "\n",
    "score AS(\n",
    "SELECT \n",
    "  s.review_score AS review_score,\n",
    "  s.sent_score AS sent_score, \n",
    "  s.sent_magnitude AS sent_magnitude,\n",
    "  s.entities_list AS entities_list,\n",
    "  s.sentences_count AS sentences_count,\n",
    "  s.token_count AS token_count,\n",
    "  s.sentlist AS sentlist,\n",
    "  s.tokenlist AS tokenlist,\n",
    "  s.review_answer_timestamp AS review_answer_timestamp,\n",
    "  s.order_id AS order_id\n",
    "FROM `<PROJECT_ID>.olist.order_reviews2` s RIGHT JOIN tmp ON s.review_answer_timestamp=tmp.max_review_answer_date AND s.order_id=tmp.order_id\n",
    "),\n",
    "\n",
    "avgr AS(\n",
    "SELECT \n",
    "  order_id,\n",
    "  COUNT(*) as num_duplicate_rows,\n",
    "  STRING_AGG(message1, \" \") as message,\n",
    "  STRING_AGG(title11, \" \") as title,\n",
    "  MIN(review_creation_date) as min_review_create_date,\n",
    "  MAX(review_creation_date) as max_review_create_date,\n",
    "  MIN(review_answer_timestamp) as min_review_answer_date,\n",
    "  MAX(review_answer_timestamp) as max_review_answer_date\n",
    "  \n",
    "FROM `<PROJECT_ID>.olist.order_reviews2` \n",
    "\n",
    "GROUP BY\n",
    "  order_id)\n",
    "\n",
    "#HAVING num_duplicate_rows > 1)\n",
    "\n",
    "SELECT \n",
    "avgr.*,\n",
    "score.review_score,\n",
    "score.sent_score AS sent_score, \n",
    "score.sent_magnitude AS sent_magnitude,\n",
    "score.entities_list AS entities_list,\n",
    "score.sentences_count AS sentences_count,\n",
    "score.token_count AS token_count,\n",
    "score.sentlist AS sentlist,\n",
    "score.tokenlist AS tokenlist,\n",
    "FROM avgr LEFT JOIN score ON avgr.order_id=score.order_id\n",
    "\"\"\"\n",
    "\n",
    "# и затем его присоединяем к orders:\n",
    "\"\"\"\n",
    "WITH tmp AS (\n",
    "SELECT \n",
    "  MAX(review_answer_timestamp) as max_review_answer_date,\n",
    "  order_id\n",
    "  FROM `<PROJECT_ID>.olist.order_reviews2`\n",
    "GROUP BY\n",
    "  order_id),\n",
    "\n",
    "score AS(\n",
    "SELECT \n",
    "  s.review_score AS review_score,\n",
    "  s.sent_score AS sent_score, \n",
    "  s.sent_magnitude AS sent_magnitude,\n",
    "  s.entities_list AS entities_list,\n",
    "  s.sentences_count AS sentences_count,\n",
    "  s.token_count AS token_count,\n",
    "  s.sentlist AS sentlist,\n",
    "  s.tokenlist AS tokenlist,\n",
    "  s.review_answer_timestamp AS review_answer_timestamp,\n",
    "  s.order_id AS order_id\n",
    "FROM `<PROJECT_ID>.olist.order_reviews2` s RIGHT JOIN tmp ON s.review_answer_timestamp=tmp.max_review_answer_date AND s.order_id=tmp.order_id\n",
    "),\n",
    "\n",
    "avgr AS(\n",
    "SELECT \n",
    "  order_id,\n",
    "  COUNT(*) as num_duplicate_rows,\n",
    "  STRING_AGG(message1, \" \") as message,\n",
    "  STRING_AGG(title11, \" \") as title,\n",
    "  MIN(review_creation_date) as min_review_create_date,\n",
    "  MAX(review_creation_date) as max_review_create_date,\n",
    "  MIN(review_answer_timestamp) as min_review_answer_date,\n",
    "  MAX(review_answer_timestamp) as max_review_answer_date\n",
    "  \n",
    "FROM `<PROJECT_ID>.olist.order_reviews2` \n",
    "\n",
    "GROUP BY\n",
    "  order_id),\n",
    "\n",
    "rev AS (\n",
    "SELECT \n",
    "avgr.*,\n",
    "score.review_score,\n",
    "score.sent_score AS sent_score, \n",
    "score.sent_magnitude AS sent_magnitude,\n",
    "score.entities_list AS entities_list,\n",
    "score.sentences_count AS sentences_count,\n",
    "score.token_count AS token_count,\n",
    "score.sentlist AS sentlist,\n",
    "score.tokenlist AS tokenlist,\n",
    "FROM avgr LEFT JOIN score ON avgr.order_id=score.order_id)\n",
    "\n",
    "SELECT \n",
    "    s.*,\n",
    "    rev.* EXCEPT (order_id)\n",
    "FROM `<PROJECT_ID>.olist.orders_full` s LEFT JOIN rev ON s.order_id=rev.order_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# к таблице customers добавляем средние долготу и широту по ZIP-коду\n",
    "\"\"\"\n",
    "#standardSQL\n",
    "WITH geoavg AS (SELECT \n",
    "  geolocation_zip_code_prefix,\n",
    "  AVG(geolocation_lat) AS lat,\n",
    "  AVG(geolocation_lng) AS lng\n",
    "FROM <PROJECT_ID>.olist.geolocation\n",
    "GROUP BY\n",
    "    geolocation_zip_code_prefix)  \n",
    "\n",
    "\n",
    "SELECT \n",
    "    c.*, \n",
    "    geoavg.lat AS customers_geo_lat,\n",
    "    geoavg.lng AS customers_geo_lng\n",
    "FROM <PROJECT_ID>.olist.customers c LEFT JOIN geoavg ON c.customer_zip_code_prefix=geoavg.geolocation_zip_code_prefix;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# к orders добавляем customers_geo \n",
    "\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "    ord.*, \n",
    "    c.* EXCEPT(customer_id)\n",
    "FROM <PROJECT_ID>.olist.orders ord LEFT JOIN <PROJECT_ID>.olist.customers_geo c ON ord.customer_id=c.customer_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# к orders добавляем некоторые агрегированные значения из order-items\n",
    "\"\"\"\n",
    "#standardSQL\n",
    "WITH itemavg AS (SELECT \n",
    "  order_id,\n",
    "  MAX(order_item_id) AS order_item_count,\n",
    "  SUM(price) AS sum_price,\n",
    "  SUM(freight_value) AS sum_freight_value,\n",
    "  SUM(price)+SUM(freight_value) AS sum_price_freight\n",
    "\n",
    "FROM `<PROJECT_ID>.olist.order_items_full`\n",
    "GROUP BY\n",
    "    order_id)  \n",
    "\n",
    "\n",
    "SELECT \n",
    "    o.*, \n",
    "    itemavg.* EXCEPT (order_id)\n",
    "FROM `<PROJECT_ID>.olist.orders_customers` o LEFT JOIN itemavg ON o.order_id=itemavg.order_id;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сколько заказов, в которых более одного уникального продукта\n",
    "\"\"\"\n",
    "WITH ordprod AS (\n",
    "SELECT \n",
    "  COUNT(*) as num_duplicate_rows,\n",
    "  order_id,\n",
    "  product_id\n",
    "  FROM <PROJECT_ID>.olist.order_items_full\n",
    "\n",
    "GROUP BY\n",
    "  order_id, \n",
    "  product_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  COUNT(*) as num_rows,\n",
    "  order_id,\n",
    "  FROM ordprod\n",
    "\n",
    "GROUP BY\n",
    "  order_id\n",
    "\n",
    "HAVING num_rows > 1\n",
    "ORDER BY num_rows DESC\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем этот показатель к orders - это заказы, для которых нет записей в order-items, т.е. нет данных о продукте и поставщике. 775 заказов\n",
    "\"\"\"\n",
    "WITH ordprod AS (\n",
    "SELECT \n",
    "  COUNT(*) as num_duplicate_rows,\n",
    "  order_id,\n",
    "  product_id\n",
    "  FROM <PROJECT_ID>.olist.order_items_full\n",
    "\n",
    "GROUP BY\n",
    "  order_id, \n",
    "  product_id\n",
    "),\n",
    "\n",
    "unprod AS(\n",
    "SELECT \n",
    "  COUNT(*) as num_uniq_prod,\n",
    "  order_id,\n",
    "  FROM ordprod\n",
    "\n",
    "GROUP BY\n",
    "  order_id)\n",
    "\n",
    "SELECT \n",
    "    o.*, \n",
    "    unprod.* EXCEPT (order_id)\n",
    "FROM `<PROJECT_ID>.olist.orders_full_reviews` o LEFT JOIN unprod ON o.order_id=unprod.order_id\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Итоговый запрос для создания расширенной таблицы orders1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "#standardSQL\n",
    "WITH geoavg AS (SELECT \n",
    "  geolocation_zip_code_prefix,\n",
    "  AVG(geolocation_lat) AS lat,\n",
    "  AVG(geolocation_lng) AS lng\n",
    "FROM `celestial-digit-321306.olist.geolocation`\n",
    "GROUP BY\n",
    "    geolocation_zip_code_prefix),  \n",
    "\n",
    "custgeo AS (\n",
    "SELECT \n",
    "    c.*, \n",
    "    geoavg.lat AS customers_geo_lat,\n",
    "    geoavg.lng AS customers_geo_lng\n",
    "FROM `<PROJECT_ID>.olist.customers` c LEFT JOIN geoavg ON c.customer_zip_code_prefix=geoavg.geolocation_zip_code_prefix),\n",
    "\n",
    "ordcustgeo AS (\n",
    "SELECT\n",
    "    ord.*, \n",
    "    c.* EXCEPT(customer_id)\n",
    "FROM `<PROJECT_ID>.olist.orders` ord LEFT JOIN custgeo c ON ord.customer_id=c.customer_id),\n",
    "\n",
    "itemavg AS (SELECT \n",
    "  order_id,\n",
    "  MAX(order_item_id) AS order_item_count,\n",
    "  SUM(price) AS sum_price,\n",
    "  SUM(freight_value) AS sum_freight_value,\n",
    "  SUM(price)+SUM(freight_value) AS sum_price_freight\n",
    "\n",
    "FROM `<PROJECT_ID>.olist.order_items1`\n",
    "GROUP BY\n",
    "    order_id),  \n",
    "\n",
    "orditem1 AS (\n",
    "SELECT \n",
    "    o.*, \n",
    "    itemavg.* EXCEPT (order_id)\n",
    "FROM ordcustgeo o LEFT JOIN itemavg ON o.order_id=itemavg.order_id),\n",
    "\n",
    "ordprod AS (\n",
    "SELECT \n",
    "  COUNT(*) as num_prod,\n",
    "  order_id,\n",
    "  product_id\n",
    "  FROM `<PROJECT_ID>.olist.order_items1`\n",
    "\n",
    "GROUP BY\n",
    "  order_id, \n",
    "  product_id\n",
    "),\n",
    "\n",
    "unprod AS(\n",
    "SELECT \n",
    "  COUNT(*) as num_uniq_prod,\n",
    "  order_id,\n",
    "  FROM ordprod\n",
    "\n",
    "GROUP BY\n",
    "  order_id),\n",
    "\n",
    "orditem2 AS (\n",
    "SELECT \n",
    "    o.*, \n",
    "    unprod.* EXCEPT (order_id)\n",
    "FROM orditem1 o LEFT JOIN unprod ON o.order_id=unprod.order_id),\n",
    "\n",
    "tmp AS (\n",
    "SELECT \n",
    "  MAX(review_answer_timestamp) as max_review_answer_date,\n",
    "  order_id\n",
    "  FROM `<PROJECT_ID>.olist.order_reviews2`\n",
    "GROUP BY\n",
    "  order_id),\n",
    "\n",
    "score AS(\n",
    "SELECT \n",
    "  s.review_score AS review_score,\n",
    "  s.sent_score AS sent_score, \n",
    "  s.sent_magnitude AS sent_magnitude,\n",
    "  s.entities_list AS entities_list,\n",
    "  s.sentences_count AS sentences_count,\n",
    "  s.token_count AS token_count,\n",
    "  s.sentlist AS sentlist,\n",
    "  s.tokenlist AS tokenlist,\n",
    "  s.review_id AS review_id,\n",
    "  s.review_answer_timestamp AS review_answer_timestamp,\n",
    "  s.order_id AS order_id\n",
    "FROM `<PROJECT_ID>.olist.order_reviews2` s RIGHT JOIN tmp ON s.review_answer_timestamp=tmp.max_review_answer_date AND s.order_id=tmp.order_id\n",
    "),\n",
    "\n",
    "avgr AS(\n",
    "SELECT \n",
    "  order_id,\n",
    "  COUNT(*) as num_reviews_per_order,\n",
    "  STRING_AGG(message1, \" \") as message,\n",
    "  STRING_AGG(title11, \" \") as title,\n",
    "  MIN(review_creation_date) as min_review_create_date,\n",
    "  MAX(review_creation_date) as max_review_create_date,\n",
    "  MIN(review_answer_timestamp) as min_review_answer_date,\n",
    "  MAX(review_answer_timestamp) as max_review_answer_date\n",
    "  \n",
    "FROM `<PROJECT_ID>.olist.order_reviews2` \n",
    "\n",
    "GROUP BY\n",
    "  order_id),\n",
    "\n",
    "rev AS (\n",
    "SELECT \n",
    "avgr.*,\n",
    "score.review_id AS review_id,\n",
    "score.review_score,\n",
    "score.sent_score AS sent_score, \n",
    "score.sent_magnitude AS sent_magnitude,\n",
    "score.entities_list AS entities_list,\n",
    "score.sentences_count AS sentences_count,\n",
    "score.token_count AS token_count,\n",
    "score.sentlist AS sentlist,\n",
    "score.tokenlist AS tokenlist,\n",
    "FROM avgr LEFT JOIN score ON avgr.order_id=score.order_id)\n",
    "\n",
    "SELECT \n",
    "    s.*,\n",
    "    rev.* EXCEPT (order_id)\n",
    "FROM orditem2 s LEFT JOIN rev ON s.order_id=rev.order_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# анализируем статус заказов\n",
    "\"\"\"\n",
    "WITH ordprod AS (\n",
    "SELECT \n",
    "  COUNT(*) as num_duplicate_rows,\n",
    "  order_id,\n",
    "  product_id\n",
    "  FROM <PROJECT_ID>.olist.order_items_full\n",
    "\n",
    "GROUP BY\n",
    "  order_id, \n",
    "  product_id\n",
    "),\n",
    "\n",
    "unprod AS(\n",
    "SELECT \n",
    "  COUNT(*) as num_uniq_prod,\n",
    "  order_id,\n",
    "  FROM ordprod\n",
    "\n",
    "GROUP BY\n",
    "  order_id),\n",
    "\n",
    "notitems AS(\n",
    "SELECT \n",
    "    o.*, \n",
    "    unprod.* EXCEPT (order_id)\n",
    "FROM `<PROJECT_ID>.olist.orders_full_reviews` o LEFT JOIN unprod ON o.order_id=unprod.order_id\n",
    "WHERE num_uniq_prod is NULL)\n",
    "\n",
    "SELECT \n",
    "COUNT(*) as num_po_cat,\n",
    "order_status\n",
    "FROM notitems \n",
    "GROUP BY order_status\n",
    "\"\"\"\n",
    "# основная масса заказов без указания продукта и поставщика - Недоступно и Отменено. И оценки соответственно в основном плохие\n",
    "\"\"\"\n",
    "Row\tnum_po_cat\torder_status\t\n",
    "1\t603 unavailable\n",
    "2\t164 canceled\n",
    "3\t5 created\n",
    "4\t1 shipped\n",
    "5\t2 invoiced\n",
    "\"\"\"\n",
    "# заказы же с указанными продуктами в основном либо доставлены, либо на разных стадиях обработки. А также есть часть отмененных\n",
    "\"\"\"\n",
    "Row\tnum_po_cat\torder_status\t\n",
    "1\t96478 delivered\n",
    "2\t461 canceled\n",
    "3\t1106 shipped\n",
    "4\t301 processing\n",
    "5\t312 invoiced\n",
    "6\t6 unavailable\n",
    "7\t2 approved\n",
    "\"\"\"\n",
    "# т.е. статус заказа сильно влияет на вероятность получения плохой оценки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
